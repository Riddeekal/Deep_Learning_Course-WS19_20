{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s7KglWQgn6lS"
   },
   "source": [
    "Deep Learning Lab 02 - Neural Network Basics\n",
    "# Implementing a Multi-layer Perceptron in NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qjCeYQjBbTt6"
   },
   "source": [
    "## 0 - Packages\n",
    "import the packages to be used:\n",
    "\n",
    "Set the numpy random seed to 42 so that the results are consistent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-Izy9aiBbw7Z"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(42) # set a seed so that the results are consistent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5uEnphavZQHg"
   },
   "source": [
    "BTW: Line numbers can be enabled by pressing `CTRL`+`M`+`L`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h9fo1qGrT9_w"
   },
   "source": [
    "## 1 - Obtaining the Image Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q8TNYq0uopKY"
   },
   "source": [
    "Execute the function below to download the dataset to be used in this lab to `/tmp/binary_flowers.npz`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "F1C-RnD1UtMj"
   },
   "outputs": [],
   "source": [
    "#@title dataset downloader\n",
    "import requests\n",
    "\n",
    "def download_file_from_google_drive(id, destination):\n",
    "    URL = \"https://docs.google.com/uc?export=download\"\n",
    "    session = requests.Session()\n",
    "    response = session.get(URL, params = { 'id' : id }, stream = True)\n",
    "    token = get_confirm_token(response)\n",
    "    if token:\n",
    "        params = { 'id' : id, 'confirm' : token }\n",
    "        response = session.get(URL, params = params, stream = True)\n",
    "    save_response_content(response, destination)\n",
    "\n",
    "def get_confirm_token(response):\n",
    "    for key, value in response.cookies.items():\n",
    "        if key.startswith('download_warning'):\n",
    "            return value\n",
    "    return None\n",
    "\n",
    "def save_response_content(response, destination):\n",
    "    CHUNK_SIZE = 32768\n",
    "    with open(destination, \"wb\") as f:\n",
    "        for chunk in response.iter_content(CHUNK_SIZE):\n",
    "            if chunk: # filter out keep-alive new chunks\n",
    "                f.write(chunk)\n",
    "\n",
    "download_file_from_google_drive('1BoDcLIEqfb9qD5VJBKr4BhArluPyOBrh', '/tmp/binary_flowers.npz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SPJtpEXUXWIq"
   },
   "source": [
    "The dataset is provided as archive of numpy arrays, each stored as binary file. Unpack them to `X_train, y_train, X_test, y_test`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U4LAeQGhVY76"
   },
   "outputs": [],
   "source": [
    "with np.load('/tmp/binary_flowers.npz') as data:\n",
    "    X_train, y_train, X_test, y_test = [ data[key] for key in ['X_train', 'y_train', 'X_test', 'y_test'] ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tyVkFUskX7s6"
   },
   "source": [
    "Plot some images to get an idea about the task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B6G_KrfDXjll"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=2, ncols=5, sharex=True, sharey=True,)\n",
    "fig.set_size_inches(14, 8)\n",
    "ax = ax.flatten()\n",
    "for class_ in range(2):\n",
    "  for sample_ in range(5):\n",
    "    img = X_train[y_train == class_][sample_] + .5\n",
    "    ax[5*class_ + sample_].axis('Off')\n",
    "    ax[5*class_ + sample_].imshow(img)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xsrakDD-_Abw"
   },
   "source": [
    "How many training examples do you have? In addition, what is the `shape` of the variables `X_train` and `y_train`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aVokXOW-5cMz"
   },
   "outputs": [],
   "source": [
    "print('Number training examples:', X_train.shape[0])\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MsJUxJFEdA4t"
   },
   "source": [
    "### Vectorization over Training Examples\n",
    "\n",
    "In order to vectorize the code, reshape the images of shape `(n_samples, width, height, channels)` to an array of shape `(n_features, n_samples)`\n",
    "\n",
    "Reshape the training and test data. Evaluate your result by plotting the first training sample. For plotting as image, you'll again have to reshape to an array of shape `(width, height, channels)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "587Mlhfxc_zG"
   },
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "\n",
    "X_train.shape = (X_train.shape[0], np.product(X_train.shape[1:]))\n",
    "X_train = X_train.T\n",
    "\n",
    "X_test.shape = (X_test.shape[0], np.product(X_test.shape[1:]))\n",
    "X_test = X_test.T\n",
    "\n",
    "print(X_train.shape, X_test.shape)\n",
    "plt.imshow(X_train[:, 0].reshape(64,64,3) + .5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kER-FRHybzWP"
   },
   "source": [
    "## 2 - Implementing a 2 Layer Neural Network\n",
    "\n",
    "Implement the neural network.\n",
    "\n",
    "Complete the implementation of the class NeuralNet and its functions based on our discussion.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-cg40CVgYpK4"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "class NeuralNet():\n",
    "  '''Feed-forward neural network with 1 hidden layer\n",
    "  \n",
    "  Parameters\n",
    "  ------------\n",
    "  n_hidden : int (default:10)\n",
    "  l2_lambda : float (default: .01)\n",
    "        Lambda value for L2-regularization.\n",
    "  epochs : int (default: 20)\n",
    "        Number of runs over the complete training set.\n",
    "  alpha : float (default: .001)\n",
    "        Learning rate\n",
    "  shuffle : bool (default: True)\n",
    "        If true, training data is shuffled every epoch.\n",
    "  minibatch_size : int (default: 1)\n",
    "      Number of training samples per minibatch.\n",
    "  seed : int (default: None)\n",
    "      Random seed for initializing weights and shuffling.\n",
    "\n",
    "  Attributes\n",
    "  ------------\n",
    "  eval_ : dict\n",
    "    Dictionary collecting the cost, training accuracy,\n",
    "    and validation accuracy for every training epoch.\n",
    "  '''\n",
    "\n",
    "  def __init__(self, n_hidden=10,\n",
    "               l2_lambda=.01, epochs=20, \n",
    "               alpha=.001, shuffle=True,\n",
    "               minibatch_size=1, seed=None):\n",
    "    \n",
    "    self.random = np.random.RandomState(seed)\n",
    "    self.n_hidden = n_hidden\n",
    "    self.l2_lambda = l2_lambda\n",
    "    self.epochs = epochs\n",
    "    self.alpha = alpha\n",
    "    self.shuffle = shuffle\n",
    "    self.minibatch_size = minibatch_size\n",
    "    self._number_of_parameters = None\n",
    "\n",
    "  def _sigmoid(self, z):\n",
    "    '''Compute sigmoid (logistic) function'''\n",
    "    return 1/(1+np.exp(-z))\n",
    "\n",
    "  def _forward(self, X):\n",
    "    '''Compute forward propagation step'''\n",
    "\n",
    "    # Step 1: net input of hidden layer\n",
    "    # (n_hidden, n_features) dot (n_features, n_samples) => (n_hidden, n_samples)\n",
    "    z_hidden = np.dot( self.w_hidden, X ) + self.b_hidden\n",
    "\n",
    "    # Step 2: activation of hidden layer\n",
    "    a_hidden = self._sigmoid( z_hidden )\n",
    "\n",
    "    # Step 3: input of output layer\n",
    "    # (n_output, n_hidden) dot (n_hidden, n_samples) => (n_output, n_samples)\n",
    "    z_output = np.dot( self.w_output, a_hidden) + self.b_output\n",
    "\n",
    "    # Step 4: activation of output layer\n",
    "    a_output = self._sigmoid( z_output )\n",
    "\n",
    "    return z_hidden, a_hidden, z_output, a_output\n",
    "\n",
    "  def _compute_cost(self, y, output):\n",
    "    '''Compute the cost function.\n",
    "\n",
    "    Parameters\n",
    "    ------------\n",
    "    y : array, shape = (n_samples,)\n",
    "        Array of binary labels.\n",
    "    output : array, shape = (n_samples,)\n",
    "        Activation of the output layer.\n",
    "\n",
    "    Returns\n",
    "    ---------\n",
    "    cost : float\n",
    "        (Regularized) cost of the output.\n",
    "    '''\n",
    "\n",
    "    L2_term = ( self.l2_lambda * \n",
    "               (np.sum(self.w_hidden ** 2.) + \n",
    "                np.sum(self.w_output ** 2.)) )\n",
    "    \n",
    "    cost = - y * np.log(output) - (1-y)*np.log(1-output) + L2_term\n",
    "\n",
    "    return cost\n",
    "\n",
    "  def predict(self, X):\n",
    "    '''Predict class labels\n",
    "    \n",
    "    Parameters\n",
    "    ------------\n",
    "    X : array, shape = (n_features, n_samples)\n",
    "        Original input features.\n",
    "        \n",
    "    Returns\n",
    "    ---------\n",
    "    y_prediction : array, shape = (n_samples)\n",
    "        Predicted boolean label.\n",
    "    '''\n",
    "    \n",
    "    z_hidden, a_hidden, z_output, a_output = self._forward(X)\n",
    "    y_prediction = np.round( a_output )\n",
    "    \n",
    "    return y_prediction\n",
    "  \n",
    "  def initialize_weights(self, n_features):\n",
    "    '''Initialize weights of the hidden and output layer\n",
    "\n",
    "    Parameters\n",
    "    ------------\n",
    "    n_features : int\n",
    "        Number of input features.\n",
    "    '''\n",
    "    # Weights of the hidden layer\n",
    "    self.w_hidden = np.random.normal(scale = .1, size=(self.n_hidden, n_features))\n",
    "    self.b_hidden = np.zeros( (self.n_hidden, 1) )\n",
    "    \n",
    "    # Weights of the output layer\n",
    "    self.w_output = np.random.normal(scale = .1, size=(1, self.n_hidden))\n",
    "    self.b_output = np.zeros( (1, 1) )\n",
    "    \n",
    "    print('Network initialized. Total number of parameters: {}'.format(self.number_of_parameters))\n",
    "\n",
    "  @property\n",
    "  def number_of_parameters(self):\n",
    "    if hasattr(self, 'w_hidden'):\n",
    "      self._number_of_parameters = np.sum([layer.size for layer in (\n",
    "          self.w_hidden, self.b_hidden, self.w_output, self.b_output)])\n",
    "    else:\n",
    "      print('No network parameters found.')\n",
    "    return self._number_of_parameters\n",
    "\n",
    "  def plot_loss(self):\n",
    "    if not hasattr(self, 'eval_'):\n",
    "      print('No evaluation history found. Run `.fit` to train your model.')\n",
    "      return\n",
    "    plt.plot(range(self.epochs), self.eval_['cost'])\n",
    "    plt.ylabel('Cost')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.show()\n",
    "\n",
    "  def plot_accuracy(self):\n",
    "    if not hasattr(self, 'eval_'):\n",
    "      print('No evaluation history found. Run `.fit` to train your model.')\n",
    "      return\n",
    "    plt.plot(range(self.epochs), self.eval_['train_acc'], \n",
    "         label='training')\n",
    "    plt.plot(range(self.epochs), self.eval_['valid_acc'], \n",
    "            label='validation', linestyle='--')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "  def fit(self, X_train, y_train, X_valid, y_valid):\n",
    "    '''Learn weights from training data.\n",
    "\n",
    "    Parameters\n",
    "    ------------\n",
    "    X_train : array, shape = (n_features, n_samples)\n",
    "        Original input features for training.\n",
    "    y_train : array, shape = (n_samples,)\n",
    "        Array of binary labels for training.\n",
    "    X_valid : array, shape = (n_features, n_samples)\n",
    "        Original input features for validation.\n",
    "    y_valid : array, shape = (n_samples,)\n",
    "        Array of binary labels for validation.\n",
    "\n",
    "    Returns\n",
    "    ---------\n",
    "    self\n",
    "    '''\n",
    "  \n",
    "    return self\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qm-w4pm3idwK"
   },
   "source": [
    "## 3 - Testing the Forward Computation\n",
    "Now it's time to initialize the network. As no backpropagation is implemented yet (you'll do that in the next lab!), you can only compute the forward propagation.\n",
    "\n",
    "Create an instance of the class `NeuralNet` with number of hidden nodes to be 10, size of minibatch and epochs to be 100:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "trUrRfbuQJo4"
   },
   "outputs": [],
   "source": [
    "my_NN = NeuralNet(n_hidden=10, minibatch_size=100, epochs=100, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-1QbZjDojSRl"
   },
   "source": [
    "If you initialize the weights randomly, the untrained network will return random predictions.\n",
    "\n",
    "For binary classification task, random guessing should return an accuracy of 50%:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0JaoegpbQbHv"
   },
   "outputs": [],
   "source": [
    "my_NN.initialize_weights(X_test.shape[0])\n",
    "predictions = my_NN.predict(X_test)\n",
    "print('Accuracy: {:.2f}%'.format( np.mean(y_test == predictions) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g-j0TcJiLVWJ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "dl02-se (solution)",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
